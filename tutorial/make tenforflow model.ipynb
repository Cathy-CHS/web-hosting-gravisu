{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 / 공공 traindataset setting 값 \n",
    "\n",
    "train_dataset = \"cifar100\"    # cifar10, cifar100. \n",
    "model_network = \"resnet50\" # resnet50, vgg16\n",
    "\n",
    "pretrain = True  # 학습 Epoch를 적게해도 성능을 좋게 나오게 하려면 True 로 설정하세요. \n",
    " \n",
    "num_epochs = 10  # 학습 횟수입니다. \n",
    "batch_size = 16  # 본인 컴퓨터에서 메모리 이슈가 발생한다면 batch_size를 좀 더 작게 설정하세요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 77s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "# 공공 데이터셋 선택 가능 \n",
    "# 혹 자신의 이미지 데이터셋으로 모델을 학습시키고 싶다면, 그에 맞는 데이터 호출 / 전처리 코드를 작성하시면 됩니다.\n",
    "\n",
    "\n",
    "if train_dataset == 'cifar10' : \n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "    train_images = train_images.astype('float32') / 255\n",
    "    test_images = test_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "elif train_dataset == 'cifar100' : \n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
    "    train_images = train_images.astype('float32') / 255\n",
    "    test_images = test_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "# 레이블을 원-핫 인코딩으로 변환\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "train_images = train_images[:10]\n",
    "train_labels = train_labels[:10]\n",
    "test_images = test_images[:5]\n",
    "test_labels = test_labels[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "\n",
    "# 모델 정의\n",
    "\n",
    "input_size = train_images.shape[1:]\n",
    "output_size = len(train_labels[0])\n",
    "\n",
    "if model_network == 'resnet50' : \n",
    "    if pretrain == True : base_model = ResNet50(include_top=False, input_shape=input_size, weights='imagenet') \n",
    "    else : base_model = ResNet50(include_top=False, input_shape=input_size, weights=None)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(output_size, activation='softmax'))\n",
    "\n",
    "elif model_network == 'vgg16' : \n",
    "    if pretrain == True : base_model = VGG16(include_top=False, input_shape=input_size, weights='imagenet')\n",
    "    else : base_model = VGG16(include_top=False, input_shape=input_size, weights=None)\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dense(output_size, activation='softmax'))\n",
    "\n",
    "base_model.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 10s 363ms/step - loss: 4.7952 - accuracy: 0.0000e+00 - val_loss: 6.1242 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1242 - accuracy: 0.0000e+00\n",
      "Test accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.conda\\envs\\lavis\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# model compire\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=num_epochs, batch_size=batch_size, validation_data=(test_images, test_labels))\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "model.save(f'{model_network}_{train_dataset}.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
